{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZY3ZoxyTuvH"
   },
   "source": [
    "# Lab Homework 5: Neural Network Interpretability\n",
    "### 15 points total\n",
    "### Version 1.0 (November 1, 2020)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH5liNkKT_yX"
   },
   "source": [
    "Wenkai Luo (wluo14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7GPEDAwUBBF"
   },
   "source": [
    "**Instructions:**\n",
    "In this notebook you will explore the performance and interpretability of the *Best* model from the programming assingment (you will see <font color='blue'>TODO</font> annotations for where to include your answers). For this lab, **you will need the models from your HW5 programming assignment**. At the beginning of each part, we will bullet the expected deliverables for you to complete. All questions can be answered in 1-4 sentences, unless otherwise noted.\n",
    "\n",
    "\n",
    "\n",
    "*   This is an **individual** lab assignment, as it relies on models from programming assignment. **You may not work with a partner for this part of the assignment**.\n",
    "*   For this assignment, you will need to either upload the data files, data.py and models to your google drive, or work in this notebook locally with jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nW9DRZzf4Pb"
   },
   "source": [
    "## Part 0: Load data and models\n",
    "\n",
    "Once you have completed or partially completed the programming part of the assignment, you will need to load the data, models and log files of your models.\n",
    "\n",
    "You can run this notebook on a) google colab, b) the CS undergrad or graduate grid, or your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEU1BQ1pg_s9"
   },
   "source": [
    "#### a) Using Google Colab\n",
    "\n",
    "If you have enough space in your drive, you can upload all the files necessary to this assignment to your google drive and access them with your colab notebook.\n",
    "\n",
    "\n",
    "> While you could train your models and do hyperparameters sweeps on google colab, we do not recommend it as sessions are time limited and your session might terminate before models can be saved.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSXRyvSRi_LC"
   },
   "source": [
    "In order to access files you have uploaded to your Google Drive, you need to \"mount\" the drive to your google colab session. You can do so with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCi6i6PZi3hX"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrULalRXiwkG"
   },
   "source": [
    "#### b) Local Machine or Grid: Jupyter Notebook or Lab\n",
    "\n",
    "Otherwise, you can download this notebook and run it in your local directory of the programming assignment, or on the CS grid. You will need to have set up either [jupyter notebook](https://jupyter.readthedocs.io/en/latest/install/notebook-classic.html) or [lab](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqbI4l4MZnei"
   },
   "source": [
    "#### 1) Load the data. Is the task feasible given the data? That is, can a human (you) accurately classify this data? Based on these few examples, can you think of problems your model may have when classifiying?\n",
    "\n",
    "Let's load the data and visualize some of our data points. This will also help you debug whether you can access your files on the drive (if you chose option *a*). Since the dataset we're working on is a vision dataset, we can actually look at our data as images.\n",
    "\n",
    "Let's take a look at one example for each label that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Udud0VOOZYYe"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxAlJb9Umxp3"
   },
   "outputs": [],
   "source": [
    "def load(path, split, load_labels=True):\n",
    "    if load_labels:\n",
    "        labels = np.load(f'{path}/{split}.labels.npy')\n",
    "    else:\n",
    "        labels = None\n",
    "    data = np.load(f'{path}/{split}.feats.npy')\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SFfUswjXWKS"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Load data and visualize example images. \n",
    "\n",
    "#######################################################\n",
    "\n",
    "### Students Start\n",
    "data, labels = load(\"data/\", split='train') # Make this point to the correct data directory.\n",
    "dev_data, dev_labels = load(\"data/\", split='dev') # Make this point to the correct data directory. \n",
    "### Students End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZd9NJgVZpFM"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Plot some examples of the data \n",
    "\n",
    "#######################################################\n",
    "\n",
    "for label in range(8):\n",
    "    for i in range(len(labels)):\n",
    "        if int(labels[i]) == label:\n",
    "            label_idx = i\n",
    "            break\n",
    "    plt.figure()\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    ex = np.array(data[label_idx], dtype=float)\n",
    "    plt.imshow(ex.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J067hhoXZs5w"
   },
   "source": [
    "<font color='blue'>\n",
    "    TODO: replace this cell with your answer\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xXv58QzaQNi"
   },
   "source": [
    "## Interpretability: How are the models wrong?\n",
    "\n",
    "During break-out rooms we have explored interpretability and explainability and using them to explore ethical considerations of our approaches. In this section, you will explore the image [LIME implementation](https://colab.research.google.com/github/arteagac/arteagac.github.io/blob/master/blog/lime_image.ipynb#scrollTo=eF3nyAc2i-Nt) that was discussed in break-out rooms. \n",
    "\n",
    "Things to do in this part:\n",
    "\n",
    "\n",
    "1.   Implement LIME\n",
    "2.   Explore wrongly classified examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKxy-iY0y1bR"
   },
   "source": [
    "#### 2) Plot images that your model misclassified. Load your best model, and plot examples that are wrong in your dev set. Can you notice any trends?\n",
    "\n",
    "Save some of these images, we will use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvFqL8vlzMX6"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Load model, predict dev set, and explore\n",
    "#       images that your model misclisified. \n",
    "\n",
    "#######################################################\n",
    "\n",
    "import torch\n",
    "\n",
    "model = torch.load(\"path-to-model\")\n",
    "\n",
    "## predict labels for dev set\n",
    "\n",
    "## Select examples that your model misclassified\n",
    "\n",
    "\n",
    "## plot some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMsQGgLrp9MO"
   },
   "source": [
    "#### 3) Implement image LIME\n",
    "\n",
    "In one of our break-out rooms, we explored Image LIME (an implementation and detailed explanation of Image LIME can be found in [this notebook](https://colab.research.google.com/github/arteagac/arteagac.github.io/blob/master/blog/lime_image.ipynb#scrollTo=eF3nyAc2i-Nt) or this ipynb file.). Your task is to study this notebook, and adapt the implementation so that it works with our dataset and your models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJOyj9U9B3Gr"
   },
   "outputs": [],
   "source": [
    "import skimage.io \n",
    "import skimage.segmentation\n",
    "import copy\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def perturb_image(img, perturbation, segments):\n",
    "    ## Implementation should be very similar to notebook,\n",
    "    ## Make sure you keep in mind the shape of the mask!\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "\n",
    "def plot_explanation(img, class, num_top_feat=4):\n",
    "    ## Step 1: Create Perturbations\n",
    "    ##   - Keep in mind the shape of our images (28x28)\n",
    "    ##   - Keep in mind that our images are grayscale (not RGB!)\n",
    "    ##   - We will use segmentation.slic rather than segmentation.quickshift (make sure to use convert2lab=False)\n",
    "    ##   - Play around with n_segments\n",
    "\n",
    "\n",
    "\n",
    "    ## Step 2: Use model to classify perturbations\n",
    "    ##   - This is where you use function perturb_image()\n",
    "    ##   - Remember the input shape of your model: must be vectors of length 784\n",
    "\n",
    "\n",
    "\n",
    "    ## Step 3: Compute distances and weights\n",
    "    ##   - Not much to change from the notebook\n",
    "\n",
    "\n",
    "\n",
    "    ## Step 4: Fit linear classifier\n",
    "    ##   - Train a LinearRegression classifier (x= perturbations, y=logits of your model for the `class`)\n",
    "    \n",
    "\n",
    "\n",
    "    ## Step 5: Plot LIME Explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWI6Pk1EqCBr"
   },
   "source": [
    "#### 4) Explore errors. With image explanations backing your claims, explain 3 errors that your model makes on the dev set.\n",
    "\n",
    "You are welcome to be creative in how you use the functions from the previous question (e.g. for an error image, look at the class the model thought it was and compare to the explanation for what the class should be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IXSFUCbaU6p"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Plot examples and show evidence for your explanations for error 1\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VezMJKYJuvlx"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Plot examples and show evidence for your explanations for error 2\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_GJ5EwAuwKV"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Plot examples and show evidence for your explanations for error 3\n",
    "\n",
    "#######################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjAbfXvyrUoC"
   },
   "source": [
    "<font color='blue'>\n",
    "    TODO: replace this cell with your answer\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uAW4HoNrBhT"
   },
   "source": [
    "#### 5) Would you feel confident deploying a version of your model? How would better interpretability help you make ethical decisions about using your data/model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDKENtewrYmN"
   },
   "source": [
    "<font color='blue'>\n",
    "    TODO: replace this cell with your answer\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS475_Homework5_lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
